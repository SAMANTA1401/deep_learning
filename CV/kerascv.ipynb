{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # Or \"jax\" or \"torch\"!\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_cv\n",
      "  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras_cv) (24.1)\n",
      "Requirement already satisfied: absl-py in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras_cv) (2.1.0)\n",
      "Collecting regex (from keras_cv)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tensorflow-datasets in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras_cv) (4.9.7)\n",
      "Collecting keras-core (from keras_cv)\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting kagglehub (from keras_cv)\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: requests in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from kagglehub->keras_cv) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from kagglehub->keras_cv) (4.67.0)\n",
      "Requirement already satisfied: numpy in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras-core->keras_cv) (2.0.2)\n",
      "Requirement already satisfied: rich in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras-core->keras_cv) (13.9.4)\n",
      "Requirement already satisfied: namex in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras-core->keras_cv) (0.0.8)\n",
      "Requirement already satisfied: h5py in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras-core->keras_cv) (3.12.1)\n",
      "Requirement already satisfied: dm-tree in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from keras-core->keras_cv) (0.1.8)\n",
      "Requirement already satisfied: click in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
      "Requirement already satisfied: immutabledict in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (4.2.0)\n",
      "Requirement already satisfied: promise in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (5.28.3)\n",
      "Requirement already satisfied: psutil in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (18.0.0)\n",
      "Requirement already satisfied: simple-parsing in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (1.16.1)\n",
      "Requirement already satisfied: termcolor in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (2.5.0)\n",
      "Requirement already satisfied: toml in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
      "Requirement already satisfied: wrapt in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-datasets->keras_cv) (1.16.0)\n",
      "Requirement already satisfied: etils>=1.9.1 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (1.10.0)\n",
      "Requirement already satisfied: fsspec in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (6.4.5)\n",
      "Requirement already satisfied: typing_extensions in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (4.12.2)\n",
      "Requirement already satisfied: zipp in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras_cv) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from requests->kagglehub->keras_cv) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from requests->kagglehub->keras_cv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from requests->kagglehub->keras_cv) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from requests->kagglehub->keras_cv) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from click->tensorflow-datasets->keras_cv) (0.4.6)\n",
      "Requirement already satisfied: six in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from rich->keras-core->keras_cv) (2.18.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.65.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
      "Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
      "   ---------------------------------------- 0.0/650.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 650.7/650.7 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 950.8/950.8 kB 11.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Installing collected packages: regex, kagglehub, keras-core, keras_cv\n",
      "Successfully installed kagglehub-0.3.4 keras-core-0.1.7 keras_cv-0.9.0 regex-2024.11.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline with augmentations\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 3\n",
    "augmenter = keras_cv.layers.Augmenter(\n",
    "    [\n",
    "        keras_cv.layers.RandomFlip(),\n",
    "        keras_cv.layers.RandAugment(value_range=(0, 255)),\n",
    "        keras_cv.layers.CutMix(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, labels, augment=False):\n",
    "    labels = tf.one_hot(labels, NUM_CLASSES)\n",
    "    inputs = {\"images\": images, \"labels\": labels}\n",
    "    outputs = inputs\n",
    "    if augment:\n",
    "        outputs = augmenter(outputs)\n",
    "    return outputs['images'], outputs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\lenovo\\tensorflow_datasets\\rock_paper_scissors\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|██████████| 219/219 [00:24<00:00,  8.91 MiB/s]]\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:24<00:00, 12.29s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset rock_paper_scissors downloaded and prepared to C:\\Users\\lenovo\\tensorflow_datasets\\rock_paper_scissors\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = tfds.load(\n",
    "    'rock_paper_scissors',\n",
    "    as_supervised=True,\n",
    "    split=['train', 'test'],\n",
    "    data_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE).map(\n",
    "    lambda x, y: preprocess_data(x, y, augment=True),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "            tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).map(\n",
    "    preprocess_data, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "        tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/efficientnetv2/keras/efficientnetv2_b0_imagenet/2/download/config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.79k/1.79k [00:00<00:00, 911kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/efficientnetv2/keras/efficientnetv2_b0_imagenet/2/download/model.weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23.1M/23.1M [00:04<00:00, 5.58MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a model using a pretrained backbone\n",
    "backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\n",
    "    \"efficientnetv2_b0_imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.ImageClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train your model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    125\u001b[0m     outputs,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[1;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "# Train your model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
